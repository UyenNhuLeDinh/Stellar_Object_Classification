{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac41025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from scipy.stats import zscore\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, f1_score, classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30a4f6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_minus_9999(df, features):\n",
    "    return df[~(df[features] == -9999).any(axis=1)].copy()\n",
    "\n",
    "def impute_u_by_class(df, target_col='class'):\n",
    "    means = df.groupby(target_col)['u'].mean()\n",
    "    for cls, mean_val in means.items():\n",
    "        mask = (df[target_col] == cls) & (df['u'].isnull())\n",
    "        df.loc[mask, 'u'] = mean_val\n",
    "    return df\n",
    "\n",
    "def remove_outliers_iqr(df, features, threshold=2.5):\n",
    "    for col in features:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - threshold * IQR\n",
    "        upper = Q3 + threshold * IQR\n",
    "        df = df[(df[col] >= lower) & (df[col] <= upper)]\n",
    "    return df.copy()\n",
    "\n",
    "def feature_engineer(df):\n",
    "    df = df.copy()\n",
    "    df['u_g'] = df['u'] - df['g']\n",
    "    df['g_r'] = df['g'] - df['r']\n",
    "    df['r_i'] = df['r'] - df['i']\n",
    "    df['i_z'] = df['i'] - df['z']\n",
    "    return df\n",
    "\n",
    "def drop_columns(df, cols):\n",
    "    return df.drop(columns=cols, errors='ignore')\n",
    "\n",
    "DROP_COLS = ['rerun_ID', 'obj_ID', 'spec_obj_ID']\n",
    "FILTER_COLS = ['u', 'g', 'r', 'i', 'z']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ec53ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.read_csv('train.csv')\n",
    "\n",
    "le = LabelEncoder()\n",
    "final_df['class'] = le.fit_transform(final_df['class'])\n",
    "\n",
    "final_df = remove_minus_9999(final_df, FILTER_COLS)\n",
    "final_df = impute_u_by_class(final_df, target_col='class')\n",
    "final_df = remove_outliers_iqr(final_df, features=FILTER_COLS + ['MJD', 'redshift'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e341389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "X = final_df.drop(columns='class')\n",
    "y = final_df['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87c33900",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale_transform = ColumnTransformer([\n",
    "    ('scale', StandardScaler(), make_column_selector(dtype_include='number'))\n",
    "])\n",
    "\n",
    "preprocess_pipe = Pipeline([\n",
    "    ('feature_eng', FunctionTransformer(feature_engineer)),\n",
    "    ('drop_cols', FunctionTransformer(lambda df: drop_columns(df, DROP_COLS))),\n",
    "    ('scale', scale_transform)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdc54d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "Best PCA+SVC Score: 0.9587121804674691\n",
      "Best PCA+SVC Params: {'svc__C': 10, 'svc__gamma': 'scale'}\n"
     ]
    }
   ],
   "source": [
    "# === Pipeline 1: PCA + SVC ===\n",
    "pipe_svc = Pipeline([\n",
    "    ('preprocessing', preprocess_pipe),\n",
    "    ('pca', PCA(n_components=0.95)),\n",
    "    ('svc', SVC(kernel='rbf', probability=True, random_state=42))\n",
    "])\n",
    "\n",
    "params_svc = {\n",
    "    'svc__C': [1, 5, 10],\n",
    "    'svc__gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "grid_svc = GridSearchCV(pipe_svc, params_svc, cv=5, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
    "grid_svc.fit(X_train, y_train)\n",
    "print(\"Best PCA+SVC Score:\", grid_svc.best_score_)\n",
    "print(\"Best PCA+SVC Params:\", grid_svc.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf9ce47",
   "metadata": {},
   "source": [
    "This gets 0.959 on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138ac5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression F1 Macro: 0.947074130539957\n",
      "Best Parameters: {'lr__C': 10, 'lr__penalty': 'l1'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nguye\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# === Pipeline 2: Feature Selection + Logistic Regression ===\n",
    "# Pipeline with regularized Logistic Regression\n",
    "pipe_lr = Pipeline([\n",
    "    ('preprocessing', preprocess_pipe),\n",
    "    ('lr', LogisticRegression(max_iter=1000, solver='saga', random_state=42)),\n",
    "\n",
    "])\n",
    "\n",
    "# Grid: regularization strength + penalty type\n",
    "params_lr = {\n",
    "    'lr__C': [0.01, 0.1, 1.0, 10],\n",
    "    'lr__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "# GridSearch with macro F1 scoring\n",
    "grid_lr = GridSearchCV(pipe_lr, param_grid=params_lr, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "grid_lr.fit(X_train, y_train)\n",
    "\n",
    "# Results\n",
    "print(\"Best Logistic Regression F1 Macro:\", grid_lr.best_score_)\n",
    "print(\"Best Parameters:\", grid_lr.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd3fd9c",
   "metadata": {},
   "source": [
    "Score 0.955"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d586ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier Best F1 Macro: 0.9671512267609101\n",
      "Best Parameters: {'model__voting': 'hard'}\n"
     ]
    }
   ],
   "source": [
    "# === Base classifiers (with tuned parameters)\n",
    "logreg = LogisticRegression(max_iter=1000, solver='saga', C=10, penalty='l1', random_state=42)\n",
    "dt = DecisionTreeClassifier(max_depth=8, min_samples_split=4, min_samples_leaf=2, random_state=42)\n",
    "rf = RandomForestClassifier(n_estimators=150, max_depth=16, min_samples_split=2, random_state=42, n_jobs=-1)\n",
    "svm = SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=42)\n",
    "\n",
    "# === Voting Classifier (hard voting)\n",
    "vote_clf = VotingClassifier(\n",
    "    estimators=[('lr', logreg), ('dt', dt), ('rf', rf), ('svm', svm)],\n",
    "    voting='hard',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# === Pipeline\n",
    "pipeline_vote = Pipeline([\n",
    "    ('pre', preprocess_pipe),\n",
    "    ('model', vote_clf)\n",
    "])\n",
    "\n",
    "# === Fit and evaluate\n",
    "pipeline_vote.fit(X, y)\n",
    "y_pred = pipeline_vote.predict(X)\n",
    "f1 = f1_score(y, y_pred, average='macro')\n",
    "print(\"VotingClassifier F1 Macro (on full data):\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698ac357",
   "metadata": {},
   "source": [
    "This gets 0.974 on kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6aa73dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier F1 Macro (on full data): 0.9908211896764384\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# === Define Base Estimators ===\n",
    "logreg = LogisticRegression(max_iter=1000, solver='saga', C=10, penalty='l1', random_state=42)\n",
    "dt = DecisionTreeClassifier(max_depth=8, min_samples_split=4, min_samples_leaf=2, random_state=42)\n",
    "rf = RandomForestClassifier(n_estimators=150, max_depth=16, min_samples_split=2, random_state=42, n_jobs=-1)\n",
    "svm = SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=42)\n",
    "\n",
    "\n",
    "# === Define Stacking Classifier ===\n",
    "stack = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', logreg),\n",
    "        ('dt', dt),\n",
    "        ('rf', rf),\n",
    "        ('svm', svm)\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(max_iter=1000, solver='lbfgs', random_state=42),\n",
    "    passthrough=False,\n",
    "    cv=3,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# === Pipeline with Preprocessing + Model ===\n",
    "pipeline = Pipeline([\n",
    "    ('pre', preprocess_pipe),  \n",
    "    ('model', stack)\n",
    "])\n",
    "\n",
    "pipeline.fit(X,y)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "print(\"VotingClassifier F1 Macro (on full data):\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a31d952",
   "metadata": {},
   "source": [
    "score 0.977"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43bff53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VotingClassifier F1 Macro (on full data): 0.9649428341669468\n"
     ]
    }
   ],
   "source": [
    "# === Pipelines with Regularized Models\n",
    "pipe_lr = Pipeline([\n",
    "    ('pre', preprocess_pipe),\n",
    "    ('clf', LogisticRegression(max_iter=1000, solver='saga', C=10, penalty='l1', random_state=42))\n",
    "])\n",
    "\n",
    "pipe_svm = Pipeline([\n",
    "    ('pre', preprocess_pipe),\n",
    "    ('clf', SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=42))\n",
    "])\n",
    "\n",
    "# === Soft Voting Classifier\n",
    "vote = VotingClassifier(\n",
    "    estimators=[('lr', pipe_lr), ('svm', pipe_svm)],\n",
    "    voting='soft',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# === Fit and Evaluate\n",
    "vote.fit(X, y)\n",
    "y_pred = vote.predict(X)\n",
    "f1 = f1_score(y, y_pred, average='macro')\n",
    "print(\"VotingClassifier F1 Macro (on full data):\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab89e6ba",
   "metadata": {},
   "source": [
    "score 0.967\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b363976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 Macro: 0.97159078833285\n",
      "Best Params: {'gb__max_depth': 5, 'gb__n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# === Gradient Boosting Pipeline\n",
    "gb_pipe = Pipeline([\n",
    "    ('pre', preprocess_pipe),\n",
    "    ('gb', GradientBoostingClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'gb__n_estimators': [100, 200],\n",
    "    'gb__max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "grid_gb = GridSearchCV(gb_pipe, param_grid=param_grid, cv=5, scoring='f1_macro', n_jobs=-1)\n",
    "grid_gb.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best F1 Macro:\", grid_gb.best_score_)\n",
    "print(\"Best Params:\", grid_gb.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f27b42c",
   "metadata": {},
   "source": [
    "score 0.975"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d5b72294",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "test_prediction = pipeline.predict(df_test)\n",
    "y_test_kaggle = pd.DataFrame(test_prediction, columns=[\"class\"])\n",
    "y_test_kaggle.index.name = \"ID\"\n",
    "y_test_kaggle[['class']].to_csv(\"kaggle1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd768d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
