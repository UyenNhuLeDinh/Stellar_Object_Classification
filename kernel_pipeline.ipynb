{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68918592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay, f1_score, classification_report\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1db42f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Ensemble Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      GALAXY       0.97      0.98      0.97      9515\n",
      "         QSO       0.96      0.89      0.92      2395\n",
      "        STAR       0.97      0.99      0.98      3449\n",
      "\n",
      "    accuracy                           0.97     15359\n",
      "   macro avg       0.96      0.95      0.96     15359\n",
      "weighted avg       0.97      0.97      0.97     15359\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def remove_minus_9999(df, features):\n",
    "    return df[~(df[features] == -9999).any(axis=1)].copy()\n",
    "\n",
    "def impute_u_by_class(df, target_col='class'):\n",
    "    means = df.groupby(target_col)['u'].mean()\n",
    "    for cls, mean_val in means.items():\n",
    "        mask = (df[target_col] == cls) & (df['u'].isnull())\n",
    "        df.loc[mask, 'u'] = mean_val\n",
    "    return df\n",
    "\n",
    "def remove_outliers_iqr(df, features, threshold=2.5):\n",
    "    for col in features:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower = Q1 - threshold * IQR\n",
    "        upper = Q3 + threshold * IQR\n",
    "        df = df[(df[col] >= lower) & (df[col] <= upper)]\n",
    "    return df.copy()\n",
    "\n",
    "def feature_engineer(df):\n",
    "    df = df.copy()\n",
    "    df['u_g'] = df['u'] - df['g']\n",
    "    df['g_r'] = df['g'] - df['r']\n",
    "    df['r_i'] = df['r'] - df['i']\n",
    "    df['i_z'] = df['i'] - df['z']\n",
    "    return df\n",
    "\n",
    "def drop_columns(df, cols):\n",
    "    return df.drop(columns=cols, errors='ignore')\n",
    "\n",
    "DROP_COLS = ['rerun_ID', 'obj_ID', 'spec_obj_ID']\n",
    "FILTER_COLS = ['u', 'g', 'r', 'i', 'z']\n",
    "\n",
    "final_df = pd.read_csv('train.csv')\n",
    "\n",
    "le = LabelEncoder()\n",
    "final_df['class'] = le.fit_transform(final_df['class'])\n",
    "\n",
    "final_df = remove_minus_9999(final_df, FILTER_COLS)\n",
    "final_df = impute_u_by_class(final_df, target_col='class')\n",
    "final_df = remove_outliers_iqr(final_df, features=FILTER_COLS + ['MJD', 'redshift'])\n",
    "\n",
    "# Split data\n",
    "X = final_df.drop(columns='class')\n",
    "y = final_df['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# ------------ Preprocessing pipeline ------------\n",
    "scale_transform = ColumnTransformer([\n",
    "    ('scale', StandardScaler(), make_column_selector(dtype_include='number'))\n",
    "])\n",
    "\n",
    "preprocess_pipe = Pipeline([\n",
    "    ('feature_eng', FunctionTransformer(feature_engineer)),\n",
    "    ('drop_cols', FunctionTransformer(lambda df: drop_columns(df, DROP_COLS))),\n",
    "    ('scale', scale_transform),\n",
    "    ('pca', PCA(n_components=0.95))  # Optional, remove if not needed\n",
    "])\n",
    "\n",
    "# ------------ Kernel-based models ------------\n",
    "svc_rbf = Pipeline([\n",
    "    ('preprocessing', preprocess_pipe),\n",
    "    ('classifier', SVC(kernel='rbf', C=10, gamma='scale', probability=True))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# ------------ Add KNN (not kernel-based, but useful baseline) ------------\n",
    "knn = Pipeline([\n",
    "    ('preprocessing', preprocess_pipe),\n",
    "    ('classifier', KNeighborsClassifier(n_neighbors=5))\n",
    "])\n",
    "\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('svc', svc_rbf),\n",
    "        ('knn', knn)\n",
    "    ],\n",
    "    final_estimator=LogisticRegression(),\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "y_pred = stacking_clf.predict(X_test)\n",
    "print(\"Stacking Ensemble Report:\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "589c9555",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m df_test \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m test_prediction \u001b[38;5;241m=\u001b[39m\u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m y_test_kaggle \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(test_prediction, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      4\u001b[0m y_test_kaggle\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/model_selection/_search.py:597\u001b[0m, in \u001b[0;36mBaseSearchCV.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    578\u001b[0m \u001b[38;5;129m@available_if\u001b[39m(_search_estimator_has(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m    580\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Call predict on the estimator with the best found parameters.\u001b[39;00m\n\u001b[1;32m    581\u001b[0m \n\u001b[1;32m    582\u001b[0m \u001b[38;5;124;03m    Only available if ``refit=True`` and the underlying estimator supports\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;124;03m        the best found parameters.\u001b[39;00m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    598\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/validation.py:1757\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m   1754\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[0;32m-> 1757\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[0;31mNotFittedError\u001b[0m: This GridSearchCV instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "test_prediction =grid_search.predict(df_test)\n",
    "y_test_kaggle = pd.DataFrame(test_prediction, columns=[\"class\"])\n",
    "y_test_kaggle.index.name = \"ID\"\n",
    "y_test_kaggle[['class']].to_csv(\"kaggle1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67caf5ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
